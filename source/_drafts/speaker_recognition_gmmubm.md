---
title: 说话人识别#1
date: 2018-5-10 19:10:00
tags: ["说话人识别", "语音识别", "机器学习"]
---
本篇文章会介绍说话人识别的传统方法。而说到说话人识别的传统方法，第一步就是进行构建GMM-UBM模型。说话人识别简单来说可以分成两个部分，一个部分是说话人特征的提取，一个部分是判断两个说话人特征是不是属于同一个人。说话人特征的提取格外的重要，对传统方法来说，这个说话人特征是i-vector。而提取i-vector，需要对一个“更大的特征”进行因子分析，排除掉除了说话人相关的特征，保留下与说话人最相关的特征。而GMM-UBM，就是用来提取这个“更大的特征”的模型。

### 什么是GMM-UBM模型

什么是GMM-UBM模型？我们可以这样理解，UBM模型是一个更加普遍的GMM模型。而每一个人，根据自己的说话人特征，对UBM进行调整，成为一个新的独立的GMM模型。为什么不针对每个人直接训练一个GMM模型呢？那是因为我们常常会有很多未标记数据，而较少的个人数据。使用这种GMM-UBM的训练方法，能够很好地利用这些未标记的数据，并且迁移到更具体的人的身上。

训练UBM模型的方法和训练GMM的方法是一致的，都是通过EM算法，不停地更新三组GMM的参数，权重，均值，方差，最后达到收敛。而我们使用的数据是部分个人的，整体的。之后，我们再使用自适应算法，比如MAP算法，比如说MLLR算法，对原本UBM的参数进行自适应调整，结果就是我们对每一个人都适应了一个模型。之后，我们提取这个GMM模型的所有成分的均值信息，拼接起来，就可以得到那个我们需要的”最大的特征“。这个最大的特征就是均值超矢量。


### 有什么自适应算法

我们一般常用的自适应算法主要有MAP算法和MLLR算法两种。下面分别对他们进行简单的介绍。

#### MAP算法

当一个新的数据点来到的时候，我们需要首先确定当前的数据点是属于UBM分布的哪一个分量。然后，我们根据下面的公式对该分布的参数进行响应的更新，更新的公式如下所示:

其中，是超参，控制UBM和特定人语音数据之间的平衡。xn是自适应的新的个人的数据。y是当前数据特征在当前GMM之各个成分的概率。

#### MLLR算法

MAP算法有一个不好的地方，针对每一个数据点来说，它所更新的成分是固定的。而又由于实际中，一个UBM中的成分很多，因此，每次更新到的参数对比之下少太多了。于是，MLLR算法就像通过线性的方法，去训练一个统一的转换模型。
，对它的均值做一个线性的变换。

我们通过最大化它的似然函数，来求得最优的线性转换。它的似然函数如下所示。我们对它进行求导数，结果等于0,就可以求出W。同样的，我们也可以对方差做同样的操作。
